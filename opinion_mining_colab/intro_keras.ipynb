{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minería de Opiniones con Keras\n",
    "\n",
    "[Keras](https://keras.io/) es una librería de alto nivel que permite crear redes neuronales en forma muy sencilla.\n",
    "\n",
    "Para trabajar con keras primero se tiene que instalar la librería [TensorFlow](https://www.tensorflow.org/install/):\n",
    "\n",
    "pip3 install --upgrade tensorflow\n",
    "pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xiF9p08_j-1L"
   },
   "source": [
    "# Tokenizar el corpus de texto\n",
    "\n",
    "**Para este ejemplo, se asumirá que el corpus ya se encuentra pre-procesado y normalizado, sin olvidar y remarcar que esta tarea es muy importante.**\n",
    "\n",
    "**Es importante contar con un corpus de texto balanceado y con muchas frases, ya que las redes neuronales a menudo requieren grandes cantidades de datos para obtener un buen entrenamiento y por lo tanto un buen \"accuracy\". Sin embargo, a mayor tamaño del corpus, se requiere más tiempo de entrenamiento.**\n",
    "\n",
    "Antes de crear el modelo de red neuronal con Keras, es necesario separar cada texto/frase del corpus en palabras y representar cada palabra (token) por un número. \n",
    "\n",
    "Por lo tanto, se tiene que calcular la frecuencia de cada palabra (token) del corpus de texto, con el objetivo de encontrar las palabras más comunes (top) y asignarle una valor pequeño. \n",
    "\n",
    "Por ejemplo, Keras representa cada palabra (token) como un número, en dónde la palabra más común del corpus se representa con el número 1, la segunda palabra más común con el número 2, y así sucesivamente. \n",
    "\n",
    "Esto quiere decir que la numeración de las palabras (tokens) raras/inusuales/menos frecuentes tienen un valor muy alto. En la mayoría de los casos esas palabras no ayudan al entrenamiento de la red neuronal, por lo que no son de utilidad.\n",
    "\n",
    "Por otro lado, si las palabras (top) más representativas tienen valores pequeños, entonces es más fácil entrenar nuestra red neuronal con esas N-palabras más representativas, y ajustar el valor de N en caso de que sea necesario. En keras, el atributo num_words se utiliza para tomar las n_palabras más frecuentes.\n",
    "\n",
    "* num_words = es un atributo que toma en cuenta solo las n palabras mas frecuentes\n",
    "\n",
    "Una vez que se cuenta con cada palabra (token), el siguiente pasao es transformar cada palabra a una representación númerica, con un ID entero que permitirá su representación vectorial.\n",
    "\n",
    "La clase Tokenizer tiene varios métodos que ayudan a preparar el texto para que pueda usarse en el modelo de red neuronal. Entre los más importantes: \n",
    "\n",
    "* fit_on_text = construye el indice de palabras\n",
    "* text_to_secuences = convierte un texto a un array númerico\n",
    "* pad_sesequences = hace que todos los textos tengan la misma longitud (rellena con ceros)\n",
    "\n",
    "**Nota: Al cálculo de las frecuencias de cada palabra se le conoce como fitting, y su representación númerica  se le llama secuencias.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0imFU6W0j-1Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# el corpus contiene seis documentos con sus respectivas etiquetas (+,-)\n",
    "dataset = ['ME gusta este ejercicio :-)',\n",
    "           'no prepara su clase!!', \n",
    "           'no me gusta su clase.', \n",
    "           'es algo dificil de, hacer',\n",
    "           'tiene Mucho conocimiento',\n",
    "           'me gusta mucho su clase']\n",
    "etiquetas = ['positivo','negativo','negativo','negativo','positivo','positivo']\n",
    "\n",
    "nb_words = 10 # toma en cuenta solo las 10 palabras más frecuentes\n",
    "\n",
    "# crea el tokenizer con los las palabras mas frecuentes\n",
    "tokenizer = Tokenizer(num_words = nb_words) \n",
    "\n",
    "# adapta (fit) el tokenizer a los documentos\n",
    "# el tokenizer reemplaza las palabras con un ID entero para obtener\n",
    "# su representación vectorial\n",
    "tokenizer.fit_on_texts(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1520444685772,
     "user": {
      "displayName": "Raul Oramas",
      "photoUrl": "//lh3.googleusercontent.com/-qhJxdQev4gI/AAAAAAAAAAI/AAAAAAAAAfA/DYA88iohB30/s50-c-k-no/photo.jpg",
      "userId": "112881898687901104051"
     },
     "user_tz": 420
    },
    "id": "BiGtEey_j-1b",
    "outputId": "2d6bb139-f6b3-49e8-a888-affc65019e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario aprendido:\n",
      ">>> {'no': 2, 'me': 3, 'tiene': 1, 'dificil': 1, 'su': 3, 'ejercicio': 1, 'es': 1, 'este': 1, 'de': 1, 'algo': 1, 'gusta': 3, 'hacer': 1, 'clase': 3, 'conocimiento': 1, 'prepara': 1, 'mucho': 2}\n",
      ">>> 6\n",
      ">>> {'no': 5, 'me': 1, 'prepara': 16, 'dificil': 8, 'su': 2, 'tiene': 7, 'es': 10, 'este': 11, 'de': 12, 'algo': 13, 'gusta': 3, 'hacer': 14, 'clase': 4, 'conocimiento': 15, 'ejercicio': 9, 'mucho': 6}\n",
      ">>> {'no': 2, 'me': 3, 'tiene': 1, 'dificil': 1, 'su': 3, 'ejercicio': 1, 'es': 1, 'este': 1, 'de': 1, 'algo': 1, 'gusta': 3, 'hacer': 1, 'clase': 3, 'conocimiento': 1, 'prepara': 1, 'mucho': 2}\n",
      "Total palabras vocabulario: 17\n"
     ]
    }
   ],
   "source": [
    "# sumariza lo que ha aprendizo el tokenizer\n",
    "print(\"Vocabulario aprendido:\")\n",
    "print(\">>>\",tokenizer.word_counts)\n",
    "print(\">>>\",tokenizer.document_count)\n",
    "print(\">>>\",tokenizer.word_index)\n",
    "print(\">>>\",tokenizer.word_docs)\n",
    "print(\"Total palabras vocabulario:\",len(tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6qmwq6LIj-1n"
   },
   "source": [
    "Observa la salida anterior. La clase Tokenizer realiza un filtrado básico de los signos de puntuación. También es posible crear expresiones regulares para realizar un filtrado más complejo.\n",
    "\n",
    "Observa que el método texts_to_sequences convierte un texto a un array númerico (lista de índices enteros) pero tomando como base el vocabulario del tokenizador, por lo que la palabra complicado no se representará en el array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1520444687722,
     "user": {
      "displayName": "Raul Oramas",
      "photoUrl": "//lh3.googleusercontent.com/-qhJxdQev4gI/AAAAAAAAAAI/AAAAAAAAAfA/DYA88iohB30/s50-c-k-no/photo.jpg",
      "userId": "112881898687901104051"
     },
     "user_tz": 420
    },
    "id": "kTzNNwEAj-1g",
    "outputId": "2c07e9cf-dbd1-4300-cca0-7ecc1afe0d02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 9]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['me gusta este ejercicio complicado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2511,
     "status": "ok",
     "timestamp": 1520444691873,
     "user": {
      "displayName": "Raul Oramas",
      "photoUrl": "//lh3.googleusercontent.com/-qhJxdQev4gI/AAAAAAAAAAI/AAAAAAAAAfA/DYA88iohB30/s50-c-k-no/photo.jpg",
      "userId": "112881898687901104051"
     },
     "user_tz": 420
    },
    "id": "hldkv_mPj-1j",
    "outputId": "14fc3761-08fc-47f9-e17c-ad22953081ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 9], [5, 2, 4], [5, 1, 3, 2, 4], [8], [7, 6], [1, 3, 6, 2, 4]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos alimentar a la red con nuevas oraciones, se utiliza el método text_to_matrix que convierte cada frase el arreglos de igual tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4rTOlKMBj-1l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_matrix(['hola mundo java'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras cuenta con la función pad_sequences, que rellenará con ceros los espacios faltantes en cada texto para que todos los textos tengan la misma longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uHPXxP_Bj-1p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 9], [5, 2, 4], [5, 1, 3, 2, 4], [8], [7, 6], [1, 3, 6, 2, 4]]\n"
     ]
    }
   ],
   "source": [
    "# las secuencias de texto no tienen la misma longitus\n",
    "text_sec = tokenizer.texts_to_sequences(dataset)\n",
    "print(text_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 3 9]\n",
      " [0 0 5 2 4]\n",
      " [5 1 3 2 4]\n",
      " [0 0 0 0 8]\n",
      " [0 0 0 7 6]\n",
      " [1 3 6 2 4]]\n"
     ]
    }
   ],
   "source": [
    "# rellenamos los huecos con ceros para que las frases tengan la misma longitud\n",
    "padded_text = pad_sequences(text_sec)\n",
    "print(padded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 2]\n",
      " [0 0 0 0 3]\n",
      " [0 0 1 2 3]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo para jugar con num_words = 4, 8, 12 y max_pad = 5 y 10\n",
    "nb_words = 4\n",
    "max_pad = 5 \n",
    "tokenizer = Tokenizer(num_words = nb_words)\n",
    "tokenizer.fit_on_texts(dataset)\n",
    "secuences = tokenizer.texts_to_sequences(dataset)\n",
    "data = pad_sequences(secuences, maxlen = max_pad)  \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuración del modelo\n",
    "\n",
    "1. Crear un modelo secuencial vacio: Sequential()\n",
    "2. Al modelo vacío se le agregan una o más capas dependiendo de la arquitectura de red neuronal que se quiere modelar\n",
    "3. Se tiene que agregar una capa Embedding (vocabulario, vector, longitud de la secuencia)\n",
    "   La capa de salida será de 32x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10, 32, input_length=5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eN42Ndmkj-1t"
   },
   "source": [
    "# 1. Cargar y procesar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "W_uRs2Faj-1v"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import json\n",
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation, Flatten, GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "import keras\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "\n",
    "# seed for reproducing same results\n",
    "seed(1)\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ],
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSAlYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9IGRvbmVgOwogICAgfQogIH0KCiAgLy8gQWxsIGRvbmUuCiAgeWllbGQgewogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnY29tcGxldGUnLAogICAgfQogIH07Cn0KCnNjb3BlLmdvb2dsZSA9IHNjb3BlLmdvb2dsZSB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiID0gc2NvcGUuZ29vZ2xlLmNvbGFiIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIuX2ZpbGVzID0gewogIF91cGxvYWRGaWxlcywKICBfdXBsb2FkRmlsZXNDb250aW51ZSwKfTsKfSkoc2VsZik7Cg==",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1951268,
     "status": "error",
     "timestamp": 1520454203601,
     "user": {
      "displayName": "Raul Oramas",
      "photoUrl": "//lh3.googleusercontent.com/-qhJxdQev4gI/AAAAAAAAAAI/AAAAAAAAAfA/DYA88iohB30/s50-c-k-no/photo.jpg",
      "userId": "112881898687901104051"
     },
     "user_tz": 420
    },
    "id": "HgDMJNMyj-1z",
    "outputId": "e032d28c-9173-468a-b132-c1e5a71c79a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:05.992660\n"
     ]
    }
   ],
   "source": [
    "# Load the reviews and parse JSON\n",
    "t1 = datetime.now()\n",
    "with open(\"yelp_academic_dataset_review.json\") as f:\n",
    "    reviews = f.read().strip().split(\"\\n\")\n",
    "reviews = [json.loads(review) for review in reviews]\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uU4wN5sOj-12"
   },
   "outputs": [],
   "source": [
    "# Get a balanced sample of positive and negative reviews\n",
    "texts = [review['text'] for review in reviews]\n",
    "\n",
    "# Convert our 5 classes into 2 (negative or positive)\n",
    "binstars = [0 if review['stars'] <= 3 else 1 for review in reviews]\n",
    "balanced_texts = []\n",
    "balanced_labels = []\n",
    "limit = 73836 # Change this to grow/shrink the dataset\n",
    "neg_pos_counts = [0, 0]\n",
    "for i in range(len(texts)):\n",
    "    polarity = binstars[i]\n",
    "    if neg_pos_counts[polarity] < limit:\n",
    "        balanced_texts.append(texts[i])\n",
    "        balanced_labels.append(binstars[i])\n",
    "        neg_pos_counts[polarity] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "6KVVoO6cj-14",
    "outputId": "57a63b1c-e325-4794-cd91-be3a1c58913f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 73836, 1: 73836})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(balanced_labels)\n",
    "# >>> Counter({0: 100000, 1: 100000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KWqosDuj-19"
   },
   "source": [
    "# 2. Obtener tokens y word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hBXtX_6Fj-1-"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(balanced_texts)\n",
    "sequences = tokenizer.texts_to_sequences(balanced_texts)\n",
    "data = pad_sequences(sequences, maxlen=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBxzRBmGj-2P"
   },
   "source": [
    "# Modelo 1: Multilayer Perceptron, vocab = 20000, batch_size = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "nZsXMToTj-2R",
    "outputId": "0c0585ec-d884-47ab-b3c5-493a865e701e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98940 samples, validate on 48732 samples\n",
      "Epoch 1/100\n",
      "32896/98940 [========>.....................] - ETA: 1295s - loss: 0.4279 - acc: 0.8045"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iDp0_R1rj-2V"
   },
   "source": [
    "# Modelo 2: CNN, Vocab = 20000, batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7CwS0YLTj-2X",
    "outputId": "00fe7e06-bc93-45a0-89c1-f6e595f961d2"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())    \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g79OzIp0j-2e"
   },
   "source": [
    "# Modelo 3: CNN Variación en los filtros y kernel, vocab = 20000, batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "FkGFPVAwj-2g",
    "outputId": "3c59ce09-3f4b-4468-a6b8-cf1468ec7f47"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters = 32, kernel_size = 3, padding = 'same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size= 2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())    \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QpTjdtLkj-2j"
   },
   "source": [
    "# Modelo 4: CNN con GlobalMaxPooling, vocab = 20000, batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xEgl8NYEj-2l",
    "outputId": "9e2c1958-6c57-4c46-da15-cfb49e276c60"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Conv1D(filters=250, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(250, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9n7OG6rkj-2r"
   },
   "source": [
    "# Modelo 5: RNN-LSTM, vocab = 20000, batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vaeIiICWj-2s",
    "outputId": "6c7d516b-47d3-446b-861b-de186dc63737"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnnTbvZ7j-2u"
   },
   "source": [
    "# Modelo 6: CNN-LSTM, vocab = 32, batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "afjyqpaYj-2v",
    "outputId": "55cce9dd-5cd5-4505-b3b2-c8bf06c513d3"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNHfcDK8j-2z"
   },
   "source": [
    "# Modelo 7: CNN con multiples capas y neuronas, vocab = 20000, batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "yUejBopKj-2z"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(300, 3, padding = 'valid', activation='relu', strides = 2))\n",
    "model.add(Conv1D(150, 3, padding = 'valid', activation='relu', strides = 2))\n",
    "model.add(Conv1D(75, 3, padding = 'valid', activation='relu', strides = 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(150, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b1Uoi58hj-21"
   },
   "source": [
    "# Modelo 8: LSTM con otra versión, vocab = 20000, batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "PnB8Agwtj-22",
    "outputId": "8ebd9c13-6198-4f31-8c7b-f933828ddcf3"
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128,input_length = 300))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "model.add(Dense(1,activation='softmax', kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adadelta',metrics = ['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLueUUysj-25"
   },
   "source": [
    "# Modelo 9: CNN-LSTM, vocab = 20000, batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "bADg2r9cj-26",
    "outputId": "7d0fbd00-96f2-40a3-de39-388c868fb908"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "    #model.add(Embedding(max_features, EMB_VECTOR_LENGHT, input_length=MAX_SEQUENCE_LENGHT))\n",
    "model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters = 32, kernel_size = 3, padding = 'same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size= 2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=6, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.5))\n",
    "    #model.add(Flatten())\n",
    "    #128,256,512\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQzjJASaj-29"
   },
   "source": [
    "# Modelo 10: CNN, vocabulario = 20000, batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "yn_JoSmMj-29",
    "outputId": "487ed972-bee7-41c8-8856-804c569efecb"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "    #model.add(Embedding(max_features, EMB_VECTOR_LENGHT, input_length=MAX_SEQUENCE_LENGHT))\n",
    "model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters = 32, kernel_size = 3, padding = 'same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size= 2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=6, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(LSTM(256))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "    #128,256,512\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47SRkYh_j-3E"
   },
   "source": [
    "# Modelo 10: CNN, vocabulario = 20000, batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "bj8EFeWGj-3E",
    "outputId": "70acfc9a-dd20-43b9-85e5-3cf853c2b295"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters = 32, kernel_size = 3, padding = 'same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size= 2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=6, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "mcp = ModelCheckpoint(\"corpus.hdf5\", monitor=\"val_acc\", save_best_only=True, save_weights_only=False,verbose = 1)\n",
    "\n",
    "model.fit(data, np.array(balanced_labels), validation_split=0.33, epochs=100, \n",
    "                          callbacks=[earlyStopping,mcp], verbose=1, batch_size= 64)\n",
    "\n",
    "# Evalua el modelo\n",
    "scores = model.evaluate(data, np.array(balanced_labels), verbose=0)\n",
    "print(\"Evaluation result on Test Data.\")\n",
    "print(\"Loss: %.2f%%\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UMPE1ak1j-3K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "index.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
